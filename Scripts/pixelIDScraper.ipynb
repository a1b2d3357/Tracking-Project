{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to download all versions of a pixel source code given its ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a list of all cdx records of a website (also saves them in a text file)\n",
    "def basicGetCdxRecords(url, filename): #works best for small scale queries only\n",
    "    base_url = \"https://web.archive.org/cdx/search/cdx\" # Base URL of the CDX Server API\n",
    "    params = {\n",
    "        'url': url,  # URL to fetch\n",
    "        'output': 'json',      # Output format\n",
    "        'matchType': 'prefix'  # Match URLs that start with this prefix\n",
    "        #no limit variable to fetch as many versions available\n",
    "    }\n",
    "\n",
    "\n",
    "    # GET request to the API\n",
    "    response = requests.get(base_url, params=params) # each esponse contains the following information: [\"urlkey\",\"timestamp\",\"original\",\"mimetype\",\"statuscode\",\"digest\",\"length\"]\n",
    "\n",
    "    allCdxRecords = []\n",
    "    # Checks whether the requeust was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Parse the JSON response\n",
    "        with open(filename,'w') as f:\n",
    "            for record in data:\n",
    "                f.write(f\"{record}\\n\")\n",
    "                allCdxRecords.append(record)\n",
    "                # Each record represents an archived version\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "    return allCdxRecords\n",
    "\n",
    "#Returns a list of all cdx records of a website, saves them in a textfile named according to the filename, and maintaint track of the progress of the progress so far in the progress_file to continue fetching records from where they were left\n",
    "def getCdxRecords(url, filename, progress_file): #works for large-scale queries\n",
    "    base_url = \"https://web.archive.org/cdx/search/cdx\"\n",
    "    limit = 100000  # Limit per request\n",
    "    params = {\n",
    "        'url': url,\n",
    "        'output': 'json',\n",
    "        'matchType': 'prefix',\n",
    "        'limit': limit,\n",
    "        'showResumeKey': True, #The last entry returned is the resume key, which is then used to begin fetching records exactly from where they were left\n",
    "        # 'pageSize': 1  # Smallest page size\n",
    "    }\n",
    "\n",
    "    # Load progress from the progress file\n",
    "    resume_key = None\n",
    "    if os.path.exists(progress_file): #checking the progress file to see whether a resume key exists to continue progress from\n",
    "        with open(progress_file, 'r') as f:\n",
    "            resume_key = f.read().strip()\n",
    "    \n",
    "    all_cdx_records = []\n",
    "    while True:\n",
    "        if resume_key:\n",
    "            params['resumeKey'] = resume_key #updating the resume key\n",
    "        \n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if not data:\n",
    "                break\n",
    "            # print(\"Fetched Data: \",data)\n",
    "            \n",
    "            # Write the records to the file and append to the list\n",
    "            with open(filename, 'a') as f:\n",
    "                for record in data[:-1]:  # Last item may be the resume key\n",
    "                    f.write(f\"{record}\\n\")\n",
    "                    all_cdx_records.append(record)\n",
    "\n",
    "            # Update the resume key and save it to the progress file\n",
    "            resume_key = data[-1]\n",
    "            print(f\"Successfully fetched: {len(data)} records. Resume key: {resume_key}\")\n",
    "            with open(progress_file, 'w') as f:\n",
    "                f.write(resume_key[0])\n",
    "            \n",
    "            # If no more results are available, exit the loop\n",
    "            if 'resumeKey' not in params or not resume_key:\n",
    "                break\n",
    "            time.sleep(3) #To avoid sending too many requests to the server which then ends up refusing the connection\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "\n",
    "    return all_cdx_records\n",
    "\n",
    "# #downloads all webpages inside the all_archives_versions folder \n",
    "def downloadArchivedVersions(fileWithRecords, archivedDirectory): #fileWithRecords is the name of the text file with all cdx records to download, archivedDirectory is the name of directory where to save all the web pages.\n",
    "\n",
    "    wayback_base_url = \"https://web.archive.org/web/\"\n",
    "    save_dir = archivedDirectory\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with open(fileWithRecords, 'r') as f:\n",
    "        records = f.readlines()\n",
    "\n",
    "    for record in records:\n",
    "        record = eval(record.strip())  # Convert the string back to a list\n",
    "        timestamp = record[1]\n",
    "        original_url = record[2]\n",
    "\n",
    "        wayback_url = f\"{wayback_base_url}{timestamp}/{original_url}\" #A resource at the wayback has a url of this format\n",
    "        filename = f\"{timestamp}.html\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "        # Check if file already exists\n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"File already exists: {filepath}\") #to continue from saved progress\n",
    "            continue\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                response = requests.get(wayback_url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                        f.write(response.text)\n",
    "                    print(f\"Downloaded and saved: {filepath}\")\n",
    "                    break\n",
    "                elif response.status_code == 404:\n",
    "                    print(f\"File not found (404): {wayback_url}. Skipping...\")\n",
    "                    break  # Stop retrying on 404 errors since it just doesn't exist\n",
    "                else:\n",
    "                    print(f\"Failed to download {wayback_url}: {response.status_code}\")\n",
    "                    time.sleep(5) #wait before retrying\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error downloading {wayback_url}: {e}\")\n",
    "                time.sleep(5)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "url = \"https://connect.facebook.net/signals/config/\" #the url of the meta pixel\n",
    "filename = \"allPixelRecords.txt\"\n",
    "progress_file = \"progress.txt\"\n",
    "cdx_records = getCdxRecords(url, filename, progress_file)\n",
    "\n",
    "# downloadArchivedVersions(filename,'all_archived_versions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website Name</th>\n",
       "      <th>Pixel ID</th>\n",
       "      <th>Fetched Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://onepathnetwork.com/?gad_source=1&amp;gclid...</td>\n",
       "      <td>128726134153194</td>\n",
       "      <td>20240913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://react-portfolio-alpha-nine-57.vercel.app</td>\n",
       "      <td>25826907853621873</td>\n",
       "      <td>20240913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Website Name           Pixel ID  \\\n",
       "0  https://onepathnetwork.com/?gad_source=1&gclid...    128726134153194   \n",
       "1   https://react-portfolio-alpha-nine-57.vercel.app  25826907853621873   \n",
       "\n",
       "  Fetched Date  \n",
       "0     20240913  \n",
       "1     20240913  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pixel IDs from Tranc's top 10k websites. Can look at snapshots to find the ID as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the latest top 1 million websites from Tranco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# Replace with your Tranco credentials\n",
    "username = os.getenv('USERNAME')\n",
    "api_token = os.getenv('TRANCO_TOKEN')\n",
    "\n",
    "def get_latest_list_metadata():\n",
    "    url = 'https://tranco-list.eu/api/lists/date/latest'\n",
    "    try:\n",
    "        response = requests.get(url, auth=HTTPBasicAuth(username, api_token))\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data['available']:\n",
    "            return data['download']\n",
    "        else:\n",
    "            print(\"No list available at the moment.\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching latest list metadata: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_list(download_url):\n",
    "    try:\n",
    "        response = requests.get(download_url, auth=HTTPBasicAuth(username, api_token))\n",
    "        response.raise_for_status()\n",
    "        with open('tranco_top_10k.csv', 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(\"Tranco Top 10k list downloaded successfully.\")\n",
    "        # Load into DataFrame\n",
    "        df = pd.read_csv('tranco_top_10k.csv', header=None, names=['Rank', 'Domain'])\n",
    "        return df\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading Tranco list: {e}\")\n",
    "        return None\n",
    "\n",
    "download_url = get_latest_list_metadata()\n",
    "\n",
    "# If a valid URL is found, download the list\n",
    "if download_url:\n",
    "    df = download_list(download_url)\n",
    "    if df is not None:\n",
    "        print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping google.com, already processed.\n",
      "Skipping amazonaws.com, already processed.\n",
      "Skipping microsoft.com, already processed.\n",
      "Skipping facebook.com, already processed.\n",
      "Skipping akamai.net, already processed.\n",
      "Skipping a-msedge.net, already processed.\n",
      "Skipping googleapis.com, already processed.\n",
      "Skipping apple.com, already processed.\n",
      "Skipping youtube.com, already processed.\n",
      "Skipping root-servers.net, already processed.\n",
      "Skipping azure.com, already processed.\n",
      "Skipping akamaiedge.net, already processed.\n",
      "Skipping twitter.com, already processed.\n",
      "Skipping cloudflare.com, already processed.\n",
      "Skipping instagram.com, already processed.\n",
      "Skipping gstatic.com, already processed.\n",
      "Skipping office.com, already processed.\n",
      "Skipping linkedin.com, already processed.\n",
      "Skipping tiktokcdn.com, already processed.\n",
      "Skipping live.com, already processed.\n",
      "Skipping googletagmanager.com, already processed.\n",
      "Skipping googlevideo.com, already processed.\n",
      "Skipping akadns.net, already processed.\n",
      "Skipping gtld-servers.net, already processed.\n",
      "Skipping windowsupdate.com, already processed.\n",
      "Skipping fbcdn.net, already processed.\n",
      "Skipping microsoftonline.com, already processed.\n",
      "Skipping trafficmanager.net, already processed.\n",
      "Skipping doubleclick.net, already processed.\n",
      "Skipping amazon.com, already processed.\n",
      "Skipping googleusercontent.com, already processed.\n",
      "Skipping wikipedia.org, already processed.\n",
      "Skipping bing.com, already processed.\n",
      "Skipping office.net, already processed.\n",
      "Skipping fastly.net, already processed.\n",
      "Skipping apple-dns.net, already processed.\n",
      "Skipping l-msedge.net, already processed.\n",
      "Skipping domaincontrol.com, already processed.\n",
      "Skipping wordpress.org, already processed.\n",
      "Skipping googlesyndication.com, already processed.\n",
      "Skipping icloud.com, already processed.\n",
      "Skipping sharepoint.com, already processed.\n",
      "Skipping youtu.be, already processed.\n",
      "Skipping github.com, already processed.\n",
      "Skipping netflix.com, already processed.\n",
      "Skipping t-msedge.net, already processed.\n",
      "Skipping mail.ru, already processed.\n",
      "Skipping whatsapp.net, already processed.\n",
      "Skipping aaplimg.com, already processed.\n",
      "Skipping pinterest.com, already processed.\n",
      "Skipping yahoo.com, already processed.\n",
      "Skipping digicert.com, already processed.\n",
      "Skipping s-msedge.net, already processed.\n",
      "Skipping adobe.com, already processed.\n",
      "Skipping cloudfront.net, already processed.\n",
      "Skipping appsflyersdk.com, already processed.\n",
      "Skipping goo.gl, already processed.\n",
      "Skipping windows.net, already processed.\n",
      "Skipping gvt2.com, already processed.\n",
      "Skipping spotify.com, already processed.\n",
      "Skipping vimeo.com, already processed.\n",
      "Skipping tiktokv.com, already processed.\n",
      "Skipping skype.com, already processed.\n",
      "Skipping cdn77.org, already processed.\n",
      "Skipping gvt1.com, already processed.\n",
      "Skipping msn.com, already processed.\n",
      "Skipping google-analytics.com, already processed.\n",
      "Skipping whatsapp.com, already processed.\n",
      "Skipping yandex.net, already processed.\n",
      "Skipping gandi.net, already processed.\n",
      "Skipping bit.ly, already processed.\n",
      "Skipping zoom.us, already processed.\n",
      "Skipping office365.com, already processed.\n",
      "Skipping wac-msedge.net, already processed.\n",
      "Skipping wordpress.com, already processed.\n",
      "Skipping ntp.org, already processed.\n",
      "Skipping roblox.com, already processed.\n",
      "Skipping bytefcdn-oversea.com, already processed.\n",
      "Skipping cloudflare.net, already processed.\n",
      "Skipping qq.com, already processed.\n",
      "Skipping nic.ru, already processed.\n",
      "Skipping ytimg.com, already processed.\n",
      "Skipping googledomains.com, already processed.\n",
      "Skipping tiktok.com, already processed.\n",
      "Skipping edgekey.net, already processed.\n",
      "Skipping e2ro.com, already processed.\n",
      "Skipping blogspot.com, already processed.\n",
      "Skipping comcast.net, already processed.\n",
      "Skipping mozilla.org, already processed.\n",
      "Skipping cloudflare-dns.com, already processed.\n",
      "Skipping opera.com, already processed.\n",
      "Skipping reddit.com, already processed.\n",
      "Skipping unity3d.com, already processed.\n",
      "Skipping lencr.org, already processed.\n",
      "Skipping googleadservices.com, already processed.\n",
      "Skipping baidu.com, already processed.\n",
      "Skipping cdninstagram.com, already processed.\n",
      "Skipping trbcdn.net, already processed.\n",
      "Skipping snapchat.com, already processed.\n",
      "Skipping intuit.com, already processed.\n",
      "Skipping europa.eu, already processed.\n",
      "Skipping mts.ru, already processed.\n",
      "Skipping amazon-adsystem.com, already processed.\n",
      "Skipping samsung.com, already processed.\n",
      "Skipping x.com, already processed.\n",
      "Skipping t.me, already processed.\n",
      "Skipping outlook.com, already processed.\n",
      "Skipping macromedia.com, already processed.\n",
      "Skipping a2z.com, already processed.\n",
      "Skipping app-analytics-services.com, already processed.\n",
      "Skipping rocket-cdn.com, already processed.\n",
      "Skipping nih.gov, already processed.\n",
      "Skipping dropbox.com, already processed.\n",
      "Skipping tumblr.com, already processed.\n",
      "Skipping wa.me, already processed.\n",
      "Skipping app-measurement.com, already processed.\n",
      "Skipping sentry.io, already processed.\n",
      "Skipping msedge.net, already processed.\n",
      "Skipping vk.com, already processed.\n",
      "Skipping gravatar.com, already processed.\n",
      "Skipping rbxcdn.com, already processed.\n",
      "Skipping github.io, already processed.\n",
      "Skipping windows.com, already processed.\n",
      "Skipping ui.com, already processed.\n",
      "Skipping userapi.com, already processed.\n",
      "Skipping dns.google, already processed.\n",
      "Skipping bytefcdn-ttpeu.com, already processed.\n",
      "Skipping one.one, already processed.\n",
      "Skipping webex.com, already processed.\n",
      "Skipping msftncsi.com, already processed.\n",
      "Skipping xiaomi.com, already processed.\n",
      "Skipping edgesuite.net, already processed.\n",
      "Skipping nytimes.com, already processed.\n",
      "Skipping aiv-cdn.net, already processed.\n",
      "Skipping registrar-servers.com, already processed.\n",
      "Skipping ggpht.com, already processed.\n",
      "Skipping b-msedge.net, already processed.\n",
      "Skipping ttlivecdn.com, already processed.\n",
      "Skipping forms.gle, already processed.\n",
      "Skipping applovin.com, already processed.\n",
      "Skipping spo-msedge.net, already processed.\n",
      "Skipping medium.com, already processed.\n",
      "Skipping paypal.com, already processed.\n",
      "Skipping archive.org, already processed.\n",
      "Skipping flickr.com, already processed.\n",
      "Skipping apache.org, already processed.\n",
      "Skipping adnxs.com, already processed.\n",
      "Skipping nist.gov, already processed.\n",
      "Skipping epicgames.com, already processed.\n",
      "Skipping ax-msedge.net, already processed.\n",
      "Skipping telecid.ru, already processed.\n",
      "Skipping com.plus, already processed.\n",
      "Skipping criteo.com, already processed.\n",
      "Skipping meraki.com, already processed.\n",
      "Skipping dual-s-msedge.net, already processed.\n",
      "Skipping dnsowl.com, already processed.\n",
      "Skipping forbes.com, already processed.\n",
      "Skipping qlivecdn.com, already processed.\n",
      "Skipping mangosip.ru, already processed.\n",
      "Skipping soundcloud.com, already processed.\n",
      "Skipping casalemedia.com, already processed.\n",
      "Skipping miit.gov.cn, already processed.\n",
      "Skipping omtrdc.net, already processed.\n",
      "Skipping cnn.com, already processed.\n",
      "Skipping pki.goog, already processed.\n",
      "Skipping aliyuncs.com, already processed.\n",
      "Skipping myfritz.net, already processed.\n",
      "Skipping t.co, already processed.\n",
      "Skipping miui.com, already processed.\n",
      "Skipping yandex.ru, already processed.\n",
      "Skipping azurewebsites.net, already processed.\n",
      "Skipping cdn-apple.com, already processed.\n",
      "Skipping android.com, already processed.\n",
      "Skipping amazon.dev, already processed.\n",
      "Skipping taboola.com, already processed.\n",
      "Skipping gmail.com, already processed.\n",
      "Skipping tiktokcdn-us.com, already processed.\n",
      "Skipping wsdvs.com, already processed.\n",
      "Skipping theguardian.com, already processed.\n",
      "Skipping 2mdn.net, already processed.\n",
      "Skipping w3.org, already processed.\n",
      "Skipping kaspersky.com, already processed.\n",
      "Skipping adobe.io, already processed.\n",
      "Skipping wildberries.ru, already processed.\n",
      "Skipping akamaized.net, already processed.\n",
      "Skipping nginx.org, already processed.\n",
      "Skipping demdex.net, already processed.\n",
      "Skipping shifen.com, already processed.\n",
      "Skipping nflxso.net, already processed.\n",
      "Skipping ebay.com, already processed.\n",
      "Skipping vtwenty.com, already processed.\n",
      "Skipping o365filtering.com, already processed.\n",
      "Skipping elisa.fi, already processed.\n",
      "Skipping doubleverify.com, already processed.\n",
      "Skipping bbc.co.uk, already processed.\n",
      "Skipping akamaihd.net, already processed.\n",
      "Skipping 3gppnetwork.org, already processed.\n",
      "Skipping creativecommons.org, already processed.\n",
      "Skipping bbc.com, already processed.\n",
      "Skipping twitch.tv, already processed.\n",
      "Skipping nginx.com, already processed.\n",
      "Skipping roku.com, already processed.\n",
      "Skipping health.mil, already processed.\n",
      "Skipping ozon.ru, already processed.\n",
      "Skipping cisco.com, already processed.\n",
      "Skipping imdb.com, already processed.\n",
      "Skipping online.net, already processed.\n",
      "Skipping sourceforge.net, already processed.\n",
      "Skipping msftconnecttest.com, already processed.\n",
      "Skipping amazonvideo.com, already processed.\n",
      "Skipping jomodns.com, already processed.\n",
      "Skipping adriver.ru, already processed.\n",
      "Skipping mit.edu, already processed.\n",
      "Skipping salesforce.com, already processed.\n",
      "Skipping mzstatic.com, already processed.\n",
      "Skipping ivi.ru, already processed.\n",
      "Skipping edgecdn.ru, already processed.\n",
      "Skipping sciencedirect.com, already processed.\n",
      "Skipping ubuntu.com, already processed.\n",
      "Skipping shopify.com, already processed.\n",
      "Skipping b-cdn.net, already processed.\n",
      "Skipping t-mobile.com, already processed.\n",
      "Skipping scorecardresearch.com, already processed.\n",
      "Skipping arubanetworks.com, already processed.\n",
      "Skipping researchgate.net, already processed.\n",
      "Skipping taobao.com, already processed.\n",
      "Skipping washingtonpost.com, already processed.\n",
      "Skipping smartadserver.com, already processed.\n",
      "Skipping ring.com, already processed.\n",
      "Skipping stripe.com, already processed.\n",
      "Skipping crashlytics.com, already processed.\n",
      "Skipping cmediahub.ru, already processed.\n",
      "Skipping nr-data.net, already processed.\n",
      "Skipping who.int, already processed.\n",
      "Skipping hubspot.com, already processed.\n",
      "Skipping youtube-nocookie.com, already processed.\n",
      "Skipping facebook.net, already processed.\n",
      "Skipping azureedge.net, already processed.\n",
      "Skipping hp.com, already processed.\n",
      "Skipping ampproject.org, already processed.\n",
      "Skipping reg.ru, already processed.\n",
      "Skipping booking.com, already processed.\n",
      "Skipping dzeninfra.ru, already processed.\n",
      "Skipping launchdarkly.com, already processed.\n",
      "Skipping salesforceliveagent.com, already processed.\n",
      "Skipping slack.com, already processed.\n",
      "Skipping googleblog.com, already processed.\n",
      "Skipping wikimedia.org, already processed.\n",
      "Skipping wixsite.com, already processed.\n",
      "Skipping byteoversea.net, already processed.\n",
      "Skipping linktr.ee, already processed.\n",
      "Skipping canva.com, already processed.\n",
      "Skipping atomile.com, already processed.\n",
      "Skipping doi.org, already processed.\n",
      "Skipping cedexis.net, already processed.\n",
      "Skipping rubiconproject.com, already processed.\n",
      "Skipping mtgglobals.com, already processed.\n",
      "Skipping openx.net, already processed.\n",
      "Skipping issuu.com, already processed.\n",
      "Skipping alicdn.com, already processed.\n",
      "Skipping tinyurl.com, already processed.\n",
      "Skipping appsflyer.com, already processed.\n",
      "Skipping sharethrough.com, already processed.\n",
      "Skipping example.com, already processed.\n",
      "Skipping t-online.de, already processed.\n",
      "Skipping oracle.com, already processed.\n",
      "Skipping 3lift.com, already processed.\n",
      "Skipping discord.com, already processed.\n",
      "Skipping harvard.edu, already processed.\n",
      "Skipping vungle.com, already processed.\n",
      "Skipping cdc.gov, already processed.\n",
      "Skipping synology.com, already processed.\n",
      "Skipping weebly.com, already processed.\n",
      "Skipping adsrvr.org, already processed.\n",
      "Skipping google.com.br, already processed.\n",
      "Skipping netangels.ru, already processed.\n",
      "Skipping drom.ru, already processed.\n",
      "Skipping cdngslb.com, already processed.\n",
      "Skipping reuters.com, already processed.\n",
      "Skipping avast.com, already processed.\n",
      "Skipping rlcdn.com, already processed.\n",
      "Skipping opendns.com, already processed.\n",
      "Skipping godaddy.com, already processed.\n",
      "Skipping pubmatic.com, already processed.\n",
      "Skipping go.com, already processed.\n",
      "Skipping dailymail.co.uk, already processed.\n",
      "Skipping media.net, already processed.\n",
      "Skipping cdn20.com, already processed.\n",
      "Skipping ttdns2.com, already processed.\n",
      "Skipping www.gov.uk, already processed.\n",
      "Skipping amazon.co.uk, already processed.\n",
      "Skipping weibo.com, already processed.\n",
      "Skipping wiley.com, already processed.\n",
      "Skipping tiktokv.us, already processed.\n",
      "Skipping samsungqbe.com, already processed.\n",
      "Skipping slideshare.net, already processed.\n",
      "Skipping googletagservices.com, already processed.\n",
      "Skipping espn.com, already processed.\n",
      "Skipping steampowered.com, already processed.\n",
      "Skipping bidswitch.net, already processed.\n",
      "Skipping alibabadns.com, already processed.\n",
      "Skipping wbx2.com, already processed.\n",
      "Skipping media-amazon.com, already processed.\n",
      "Skipping usatoday.com, already processed.\n",
      "Skipping appcenter.ms, already processed.\n",
      "Skipping ripn.net, already processed.\n",
      "Skipping dns-parking.com, already processed.\n",
      "Skipping samsungcloud.com, already processed.\n",
      "Skipping jsdelivr.net, already processed.\n",
      "Skipping 1c.ru, already processed.\n",
      "Skipping bloomberg.com, already processed.\n",
      "Skipping nease.net, already processed.\n",
      "Skipping criteo.net, already processed.\n",
      "Skipping playstation.net, already processed.\n",
      "Skipping telegraph.co.uk, already processed.\n",
      "Skipping nature.com, already processed.\n",
      "Skipping adsafeprotected.com, already processed.\n",
      "Skipping openai.com, already processed.\n",
      "Skipping etsy.com, already processed.\n",
      "Skipping ibm.com, already processed.\n",
      "Skipping twimg.com, already processed.\n",
      "Skipping pangle.io, already processed.\n",
      "Skipping wsj.com, already processed.\n",
      "Skipping worldfcdn2.com, already processed.\n",
      "Skipping weather.com, already processed.\n",
      "Skipping azurefd.net, already processed.\n",
      "Skipping quantserve.com, already processed.\n",
      "Skipping un.org, already processed.\n",
      "Skipping hichina.com, already processed.\n",
      "Skipping notamedia.ru, already processed.\n",
      "Skipping shalltry.com, already processed.\n",
      "Skipping zendesk.com, already processed.\n",
      "Skipping lijit.com, already processed.\n",
      "Skipping samsungcloudsolution.com, already processed.\n",
      "Skipping my.com, already processed.\n",
      "Skipping dailymotion.com, already processed.\n",
      "Skipping allawnos.com, already processed.\n",
      "Skipping businessinsider.com, already processed.\n",
      "Skipping mi.com, already processed.\n",
      "Skipping dnsmadeeasy.com, already processed.\n",
      "Skipping springer.com, already processed.\n",
      "Skipping wp.com, already processed.\n",
      "Skipping google.de, already processed.\n",
      "Skipping php.net, already processed.\n",
      "Skipping inmobi.com, already processed.\n",
      "Skipping liadm.com, already processed.\n",
      "Skipping douyincdn.com, already processed.\n",
      "Skipping mcafee.com, already processed.\n",
      "Skipping ibyteimg.com, already processed.\n",
      "Skipping adform.net, already processed.\n",
      "Skipping discord.gg, already processed.\n",
      "Skipping indeed.com, already processed.\n",
      "Skipping eset.com, already processed.\n",
      "Skipping quora.com, already processed.\n",
      "Skipping sc-cdn.net, already processed.\n",
      "Skipping ea.com, already processed.\n",
      "Skipping clarity.ms, already processed.\n",
      "Skipping list-manage.com, already processed.\n",
      "Skipping dzen.ru, already processed.\n",
      "Skipping pixabay.com, already processed.\n",
      "Skipping outbrain.com, already processed.\n",
      "Skipping pages.dev, already processed.\n",
      "Skipping creativecdn.com, already processed.\n",
      "Skipping stackoverflow.com, already processed.\n",
      "Skipping nasa.gov, already processed.\n",
      "Skipping yximgs.com, already processed.\n",
      "Skipping force.com, already processed.\n",
      "Skipping independent.co.uk, already processed.\n",
      "Skipping sohu.com, already processed.\n",
      "Skipping forter.com, already processed.\n",
      "Skipping stanford.edu, already processed.\n",
      "Skipping unsplash.com, already processed.\n",
      "Skipping gnu.org, already processed.\n",
      "Skipping ksyuncdn.com, already processed.\n",
      "Skipping inner-active.mobi, already processed.\n",
      "Skipping telekom.net, already processed.\n",
      "Skipping cnbc.com, already processed.\n",
      "Skipping tripadvisor.com, already processed.\n",
      "Skipping cpanel.net, already processed.\n",
      "Skipping name-services.com, already processed.\n",
      "Skipping eventbrite.com, already processed.\n",
      "Skipping tp-link.com, already processed.\n",
      "Skipping google.co.uk, already processed.\n",
      "Skipping comfortel.pro, already processed.\n",
      "Skipping pv-cdn.net, already processed.\n",
      "Skipping nstld.com, already processed.\n",
      "Skipping sophos.com, already processed.\n",
      "Skipping xcal.tv, already processed.\n",
      "Skipping aliexpress.com, already processed.\n",
      "Skipping elasticbeanstalk.com, already processed.\n",
      "Skipping adobe.net, already processed.\n",
      "Skipping heytapdl.com, already processed.\n",
      "Skipping chatgpt.com, already processed.\n",
      "Skipping static.microsoft, already processed.\n",
      "Skipping consultant.ru, already processed.\n",
      "Skipping amazonalexa.com, already processed.\n",
      "Skipping giphy.com, already processed.\n",
      "Skipping id5-sync.com, already processed.\n",
      "Skipping xboxlive.com, already processed.\n",
      "Skipping mozilla.com, already processed.\n",
      "Skipping npr.org, already processed.\n",
      "Skipping gosuslugi.ru, already processed.\n",
      "Skipping yahoo.co.jp, already processed.\n",
      "Skipping sfx.ms, already processed.\n",
      "Skipping globo.com, already processed.\n",
      "Skipping checkpoint.com, already processed.\n",
      "Skipping sc-gw.com, already processed.\n",
      "Skipping mynetname.net, already processed.\n",
      "Skipping ok.ru, already processed.\n",
      "Skipping bilibili.com, already processed.\n",
      "Skipping dell.com, already processed.\n",
      "Skipping myshopify.com, already processed.\n",
      "Skipping kaspersky-labs.com, already processed.\n",
      "Skipping statista.com, already processed.\n",
      "Skipping isnssdk.com, already processed.\n",
      "Skipping goodreads.com, already processed.\n",
      "Skipping ys7.com, already processed.\n",
      "Skipping f5.com, already processed.\n",
      "Skipping ttvnw.net, already processed.\n",
      "Skipping cloud.microsoft, already processed.\n",
      "Skipping avcdn.net, already processed.\n",
      "Skipping dotomi.com, already processed.\n",
      "Skipping amazon.de, already processed.\n",
      "Skipping foxnews.com, already processed.\n",
      "Skipping autodesk.com, already processed.\n",
      "Skipping g.page, already processed.\n",
      "Skipping imcmdb.net, already processed.\n",
      "Skipping rambler.ru, already processed.\n",
      "Skipping nvidia.com, already processed.\n",
      "Skipping walmart.com, already processed.\n",
      "Skipping teamviewer.com, already processed.\n",
      "Skipping capcutapi.com, already processed.\n",
      "Skipping addtoany.com, already processed.\n",
      "Skipping time.com, already processed.\n",
      "Skipping telegram.org, already processed.\n",
      "Skipping indexww.com, already processed.\n",
      "Skipping firetvcaptiveportal.com, already processed.\n",
      "Skipping aliyun.com, already processed.\n",
      "Skipping tds.net, already processed.\n",
      "Skipping grammarly.com, already processed.\n",
      "Skipping byteoversea.com, already processed.\n",
      "Skipping verisign.com, already processed.\n",
      "Skipping gamepass.com, already processed.\n",
      "Skipping tradingview.com, already processed.\n",
      "Skipping naver.com, already processed.\n",
      "Skipping wired.com, already processed.\n",
      "Skipping alibaba.com, already processed.\n",
      "Skipping entrust.net, already processed.\n",
      "Skipping nflximg.com, already processed.\n",
      "Skipping accuweather.com, already processed.\n",
      "Skipping hicloud.com, already processed.\n",
      "Skipping beian.gov.cn, already processed.\n",
      "Skipping mikrotik.com, already processed.\n",
      "Skipping temu.com, already processed.\n",
      "Skipping online-metrix.net, already processed.\n",
      "Skipping kwai.net, already processed.\n",
      "Skipping speedtest.net, already processed.\n",
      "Skipping duckduckgo.com, already processed.\n",
      "Skipping wix.com, already processed.\n",
      "Skipping amzn.to, already processed.\n",
      "Skipping digitalocean.com, already processed.\n",
      "Skipping uber.com, already processed.\n",
      "Skipping telegram.me, already processed.\n",
      "Skipping blogger.com, already processed.\n",
      "Skipping vedcdnlb.com, already processed.\n",
      "Skipping duckdns.org, already processed.\n",
      "Skipping behance.net, already processed.\n",
      "Skipping ngenix.net, already processed.\n",
      "Skipping ctdns.cn, already processed.\n",
      "Skipping chinamobile.com, already processed.\n",
      "Skipping cnet.com, already processed.\n",
      "Skipping surveymonkey.com, already processed.\n",
      "Skipping scribd.com, already processed.\n",
      "Skipping mayoclinic.org, already processed.\n",
      "Skipping healthline.com, already processed.\n",
      "Skipping debian.org, already processed.\n",
      "Skipping vkuser.net, already processed.\n",
      "Skipping ft.com, already processed.\n",
      "Skipping launchpad.net, already processed.\n",
      "Skipping phicdn.net, already processed.\n",
      "Skipping expedia.com, already processed.\n",
      "Skipping trendmicro.com, already processed.\n",
      "Skipping delfi.lt, already processed.\n",
      "Skipping telekom.de, already processed.\n",
      "Skipping onlinepbx.ru, already processed.\n",
      "Skipping cloudapp.net, already processed.\n",
      "Skipping mediatek.com, already processed.\n",
      "Skipping duolingo.com, already processed.\n",
      "Skipping google.com.hk, already processed.\n",
      "Skipping ups.com, already processed.\n",
      "Skipping branch.io, already processed.\n",
      "Skipping icloud-content.com, already processed.\n",
      "Skipping rzone.de, already processed.\n",
      "Skipping indiatimes.com, already processed.\n",
      "Skipping blueapron.com, already processed.\n",
      "Skipping xvideos.com, already processed.\n",
      "Skipping ted.com, already processed.\n",
      "Skipping disqus.com, already processed.\n",
      "Skipping squarespace.com, already processed.\n",
      "Skipping akam.net, already processed.\n",
      "Skipping dnspod.net, already processed.\n",
      "Skipping ovscdns.com, already processed.\n",
      "Skipping trustpilot.com, already processed.\n",
      "Skipping huawei.com, already processed.\n",
      "Skipping mozgcp.net, already processed.\n",
      "Skipping grammarly.io, already processed.\n",
      "Skipping 360yield.com, already processed.\n",
      "Skipping hotjar.com, already processed.\n",
      "Skipping imgsmail.ru, already processed.\n",
      "Skipping aol.com, already processed.\n",
      "Skipping safebrowsing.apple, already processed.\n",
      "Skipping msidentity.com, already processed.\n",
      "Skipping google.ca, already processed.\n",
      "Skipping fandom.com, already processed.\n",
      "Skipping calendly.com, already processed.\n",
      "Skipping nypost.com, already processed.\n",
      "Skipping virtualearth.net, already processed.\n",
      "Skipping google.fr, already processed.\n",
      "Skipping intel.com, already processed.\n",
      "Skipping deviantart.com, already processed.\n",
      "Skipping sentinelone.net, already processed.\n",
      "Skipping amazontrust.com, already processed.\n",
      "Skipping mailchimp.com, already processed.\n",
      "Skipping xhamster.com, already processed.\n",
      "Skipping imgur.com, already processed.\n",
      "Skipping rackspace.net, already processed.\n",
      "Skipping mysql.com, already processed.\n",
      "Skipping cdnbuild.net, already processed.\n",
      "Skipping goskope.com, already processed.\n",
      "Skipping upwitheaway.info, already processed.\n",
      "Skipping ca.gov, already processed.\n",
      "Skipping yahoodns.net, already processed.\n",
      "Skipping vkontakte.ru, already processed.\n",
      "Skipping rakuten.co.jp, already processed.\n",
      "Skipping hostgator.com, already processed.\n",
      "Skipping adtrafficquality.google, already processed.\n",
      "Skipping buzzfeed.com, already processed.\n",
      "Skipping braze.com, already processed.\n",
      "Skipping sapo.pt, already processed.\n",
      "Skipping netease.com, already processed.\n",
      "Skipping onetrust.com, already processed.\n",
      "Skipping azure-dns.com, already processed.\n",
      "Skipping aboutads.info, already processed.\n",
      "Skipping visualstudio.com, already processed.\n",
      "Skipping uol.com.br, already processed.\n",
      "Skipping google.co.jp, already processed.\n",
      "Skipping cbsnews.com, already processed.\n",
      "Skipping oup.com, already processed.\n",
      "Skipping steamcommunity.com, already processed.\n",
      "Skipping loc.gov, already processed.\n",
      "Skipping deepintent.com, already processed.\n",
      "Skipping playstation.com, already processed.\n",
      "Skipping freepik.com, already processed.\n",
      "Skipping patreon.com, already processed.\n",
      "Skipping bdydns.com, already processed.\n",
      "Skipping jquery.com, already processed.\n",
      "Skipping netflix.net, already processed.\n",
      "Skipping tencent-cloud.net, already processed.\n",
      "Skipping line.me, already processed.\n",
      "Skipping paloaltonetworks.com, already processed.\n",
      "Skipping apnews.com, already processed.\n",
      "Skipping berkeley.edu, already processed.\n",
      "Skipping sina.com.cn, already processed.\n",
      "Skipping mega.co.nz, already processed.\n",
      "Skipping ietf.org, already processed.\n",
      "Skipping omnitagjs.com, already processed.\n",
      "Skipping kwimgs.com, already processed.\n",
      "Skipping licdn.com, already processed.\n",
      "Skipping yandex.com, already processed.\n",
      "Skipping 163.com, already processed.\n",
      "Skipping conviva.com, already processed.\n",
      "Skipping yieldmo.com, already processed.\n",
      "Skipping amazon.co.jp, already processed.\n",
      "Skipping cornell.edu, already processed.\n",
      "Skipping newsweek.com, already processed.\n",
      "Skipping cookielaw.org, already processed.\n",
      "Skipping marriott.com, already processed.\n",
      "Skipping fb.com, already processed.\n",
      "Skipping tandfonline.com, already processed.\n",
      "Skipping bigo.sg, already processed.\n",
      "Skipping noaa.gov, already processed.\n",
      "Skipping techcrunch.com, already processed.\n",
      "Skipping ezvizlife.com, already processed.\n",
      "Skipping nike.com, already processed.\n",
      "Skipping qualtrics.com, already processed.\n",
      "Skipping theverge.com, already processed.\n",
      "Skipping atlassian.com, already processed.\n",
      "Skipping newrelic.com, already processed.\n",
      "Skipping amplitude.com, already processed.\n",
      "Skipping 360.cn, already processed.\n",
      "Skipping shutterstock.com, already processed.\n",
      "Skipping ovscdns.net, already processed.\n",
      "Skipping yelp.com, already processed.\n",
      "Skipping worldnic.com, already processed.\n",
      "Skipping livejournal.com, already processed.\n",
      "Skipping agkn.com, already processed.\n",
      "Skipping myspace.com, already processed.\n",
      "Skipping rt.ru, already processed.\n",
      "Skipping go-mpulse.net, already processed.\n",
      "Skipping free.fr, already processed.\n",
      "Skipping myqcloud.com, already processed.\n",
      "Skipping smaato.net, already processed.\n",
      "Skipping moatads.com, already processed.\n",
      "Skipping wattpad.com, already processed.\n",
      "Skipping britannica.com, already processed.\n",
      "Skipping ikea.com, already processed.\n",
      "Skipping google.co.in, already processed.\n",
      "Skipping google.es, already processed.\n",
      "Skipping latimes.com, already processed.\n",
      "Skipping tapad.com, already processed.\n",
      "Skipping crwdcntrl.net, already processed.\n",
      "Skipping docker.com, already processed.\n",
      "Skipping optimizely.com, already processed.\n",
      "Skipping spov-msedge.net, already processed.\n",
      "Skipping webmd.com, already processed.\n",
      "Skipping typekit.net, already processed.\n",
      "Skipping att.net, already processed.\n",
      "Skipping google.it, already processed.\n",
      "Skipping okta.com, already processed.\n",
      "Skipping timeweb.ru, already processed.\n",
      "Skipping fontawesome.com, already processed.\n",
      "Skipping live.net, already processed.\n",
      "Skipping adobedtm.com, already processed.\n",
      "Skipping life360.com, already processed.\n",
      "Skipping contentsquare.net, already processed.\n",
      "Skipping att.com, already processed.\n",
      "Skipping byteglb.com, already processed.\n",
      "Skipping dns-shop.ru, already processed.\n",
      "Skipping svc.ms, already processed.\n",
      "Skipping wal-mart.com, already processed.\n",
      "Skipping stackadapt.com, already processed.\n",
      "Skipping ipv4only.arpa, already processed.\n",
      "Skipping galleryvalery.com, already processed.\n",
      "Skipping pandora.com, already processed.\n",
      "Skipping prnewswire.com, already processed.\n",
      "Skipping pinimg.com, already processed.\n",
      "Skipping hugedomains.com, already processed.\n",
      "Skipping w3schools.com, already processed.\n",
      "Skipping elpais.com, already processed.\n",
      "Skipping dbankcloud.com, already processed.\n",
      "Skipping cookiedatabase.org, already processed.\n",
      "Skipping usgovcloudapi.net, already processed.\n",
      "Skipping target.com, already processed.\n",
      "Skipping klaviyo.com, already processed.\n",
      "Skipping nflxvideo.net, already processed.\n",
      "Skipping sagepub.com, already processed.\n",
      "Skipping amazon.ca, already processed.\n",
      "Skipping amazon.fr, already processed.\n",
      "Skipping name.com, already processed.\n",
      "Skipping herokuapp.com, already processed.\n",
      "Skipping ieee.org, already processed.\n",
      "Skipping samsungapps.com, already processed.\n",
      "Skipping igamecj.com, already processed.\n",
      "Skipping imrworldwide.com, already processed.\n",
      "Skipping easebar.com, already processed.\n",
      "Skipping beeline.ru, already processed.\n",
      "Skipping nbcnews.com, already processed.\n",
      "Skipping cdnhwc1.com, already processed.\n",
      "Skipping mlb.com, already processed.\n",
      "Skipping bidr.io, already processed.\n",
      "Skipping nelreports.net, already processed.\n",
      "Skipping intercom.io, already processed.\n",
      "Skipping bitrix24.ru, already processed.\n",
      "Skipping e-msedge.net, already processed.\n",
      "Skipping contextweb.com, already processed.\n",
      "Skipping kaspi.kz, already processed.\n",
      "Skipping awsglobalaccelerator.com, already processed.\n",
      "Skipping 33across.com, already processed.\n",
      "Skipping cambridge.org, already processed.\n",
      "Skipping addthis.com, already processed.\n",
      "Skipping jotform.com, already processed.\n",
      "Skipping gumgum.com, already processed.\n",
      "Skipping mediafire.com, already processed.\n",
      "Skipping usda.gov, already processed.\n",
      "Skipping ks-cdn.com, already processed.\n",
      "Skipping rackspace.com, already processed.\n",
      "Skipping hbr.org, already processed.\n",
      "Skipping erome.com, already processed.\n",
      "Skipping allaboutcookies.org, already processed.\n",
      "Skipping steamstatic.com, already processed.\n",
      "Skipping investopedia.com, already processed.\n",
      "Skipping everesttech.net, already processed.\n",
      "Skipping 360safe.com, already processed.\n",
      "Skipping coinmarketcap.com, already processed.\n",
      "Skipping 1rx.io, already processed.\n",
      "Skipping bamgrid.com, already processed.\n",
      "Skipping prmsrvs.com, already processed.\n",
      "Skipping brave.com, already processed.\n",
      "Skipping shein.com, already processed.\n",
      "Skipping service.gov.uk, already processed.\n",
      "Skipping impervadns.net, already processed.\n",
      "Skipping samsungacr.com, already processed.\n",
      "Skipping fda.gov, already processed.\n",
      "Skipping washington.edu, already processed.\n",
      "Skipping fedex.com, already processed.\n",
      "Skipping teads.tv, already processed.\n",
      "Skipping datadoghq.com, already processed.\n",
      "Skipping networkadvertising.org, already processed.\n",
      "Skipping bestbuy.com, already processed.\n",
      "Skipping aws.dev, already processed.\n",
      "Skipping crpt.ru, already processed.\n",
      "Skipping appspot.com, already processed.\n",
      "Skipping comcast.com, already processed.\n",
      "Skipping unesco.org, already processed.\n",
      "Skipping zemanta.com, already processed.\n",
      "Skipping incapdns.net, already processed.\n",
      "Skipping googlezip.net, already processed.\n",
      "Skipping amazon.in, already processed.\n",
      "Skipping box.com, already processed.\n",
      "Skipping footprintdns.com, already processed.\n",
      "Skipping anydesk.com, already processed.\n",
      "Skipping xiaomi.net, already processed.\n",
      "Skipping lemonde.fr, already processed.\n",
      "Skipping olympics.com, already processed.\n",
      "Skipping gcdn.co, already processed.\n",
      "Skipping herokudns.com, already processed.\n",
      "Skipping theatlantic.com, already processed.\n",
      "Skipping cdnvideo.ru, already processed.\n",
      "Skipping sberbank.ru, already processed.\n",
      "Skipping rncdn7.com, already processed.\n",
      "Skipping bluekai.com, already processed.\n",
      "Skipping oraclecloud.com, already processed.\n",
      "Skipping spaceweb.pro, already processed.\n",
      "Skipping huffingtonpost.com, already processed.\n",
      "Skipping mixpanel.com, already processed.\n",
      "Skipping shopee.co.id, already processed.\n",
      "Skipping wb.ru, already processed.\n",
      "Skipping rbc.ru, already processed.\n",
      "Skipping udemy.com, already processed.\n",
      "Skipping youku.com, already processed.\n",
      "Skipping riotgames.com, already processed.\n",
      "Skipping pendo.io, already processed.\n",
      "Skipping nationalgeographic.com, already processed.\n",
      "Skipping warnerbros.com, already processed.\n",
      "Skipping airbnb.com, already processed.\n",
      "Skipping viber.com, already processed.\n",
      "Skipping people.com, already processed.\n",
      "Skipping nikkei.com, already processed.\n",
      "Skipping cdnhwc2.com, already processed.\n",
      "Skipping pvp.net, already processed.\n",
      "Skipping browser-intake-datadoghq.com, already processed.\n",
      "Skipping miwifi.com, already processed.\n",
      "Skipping dns.com, already processed.\n",
      "Skipping fiverr.com, already processed.\n",
      "Skipping zillow.com, already processed.\n",
      "Skipping dbankcloud.cn, already processed.\n",
      "Skipping turn.com, already processed.\n",
      "Skipping usps.com, already processed.\n",
      "Skipping a-mo.net, already processed.\n",
      "Skipping kargo.com, already processed.\n",
      "Skipping xbox.com, already processed.\n",
      "Skipping vivoglobal.com, already processed.\n",
      "Skipping omni.ru, already processed.\n",
      "Skipping avito.ru, already processed.\n",
      "Skipping quickconnect.to, already processed.\n",
      "Skipping 1drv.com, already processed.\n",
      "Skipping chartboost.com, already processed.\n",
      "Skipping tremorhub.com, already processed.\n",
      "Skipping mailchi.mp, already processed.\n",
      "Skipping google.cn, already processed.\n",
      "Skipping w55c.net, already processed.\n",
      "Skipping globalsign.com, already processed.\n",
      "Skipping yellowblue.io, already processed.\n",
      "Skipping sitescout.com, already processed.\n",
      "Skipping fast.com, already processed.\n",
      "Skipping bandcamp.com, already processed.\n",
      "Skipping cqloud.com, already processed.\n",
      "Skipping mgts.ru, already processed.\n",
      "Skipping ya.ru, already processed.\n",
      "Skipping themeforest.net, already processed.\n",
      "Skipping liftoff.io, already processed.\n",
      "Skipping homedepot.com, already processed.\n",
      "Skipping heytapmobile.com, already processed.\n",
      "Skipping isappcloud.com, already processed.\n",
      "Skipping azure-devices.net, already processed.\n",
      "Skipping news.com.au, already processed.\n",
      "Skipping bitdefender.com, already processed.\n",
      "Skipping stickyadstv.com, already processed.\n",
      "Skipping webrootcloudav.com, already processed.\n",
      "Skipping bluehost.com, already processed.\n",
      "Skipping bugsnag.com, already processed.\n",
      "Skipping zoho.com, already processed.\n",
      "Skipping mgid.com, already processed.\n",
      "Skipping plesk.com, already processed.\n",
      "Skipping discordapp.com, already processed.\n",
      "Skipping infonline.de, already processed.\n",
      "Skipping onlyfans.com, already processed.\n",
      "Skipping xnxx.com, already processed.\n",
      "Skipping ipredictive.com, already processed.\n",
      "Skipping rapid7.com, already processed.\n",
      "Skipping google.pl, already processed.\n",
      "Skipping protek.ru, already processed.\n",
      "Skipping gitlab.com, already processed.\n",
      "Skipping ioam.de, already processed.\n",
      "Skipping upwork.com, already processed.\n",
      "Skipping ssl-images-amazon.com, already processed.\n",
      "Skipping maricopa.gov, already processed.\n",
      "Skipping gandi-ns.fr, already processed.\n",
      "Skipping wyzecam.com, already processed.\n",
      "Skipping change.org, already processed.\n",
      "Skipping princeton.edu, already processed.\n",
      "Skipping heylink.me, already processed.\n",
      "Skipping hostgator.com.br, already processed.\n",
      "Skipping express.co.uk, already processed.\n",
      "Skipping cloudflareinsights.com, already processed.\n",
      "Skipping huffpost.com, already processed.\n",
      "Skipping githubusercontent.com, already processed.\n",
      "Skipping onetag-sys.com, already processed.\n",
      "Skipping pubmnet.com, already processed.\n",
      "Skipping bootstrapcdn.com, already processed.\n",
      "Skipping netgear.com, already processed.\n",
      "Skipping cloudns.net, already processed.\n",
      "Skipping epa.gov, already processed.\n",
      "Skipping shopee.com.br, already processed.\n",
      "Skipping samsungosp.com, already processed.\n",
      "Skipping spbycdn.com, already processed.\n",
      "Skipping fastly-edge.com, already processed.\n",
      "Skipping canonical.com, already processed.\n",
      "Skipping unrulymedia.com, already processed.\n",
      "Skipping redhat.com, already processed.\n",
      "Skipping kickstarter.com, already processed.\n",
      "Skipping iso.org, already processed.\n",
      "Skipping lefigaro.fr, already processed.\n",
      "Skipping ebay.co.uk, already processed.\n",
      "Skipping fbsbx.com, already processed.\n",
      "Skipping lenovo.com, already processed.\n",
      "Skipping adnxs.net, already processed.\n",
      "Skipping pbs.org, already processed.\n",
      "Skipping bild.de, already processed.\n",
      "Skipping amazon.es, already processed.\n",
      "Skipping scdn.co, already processed.\n",
      "Skipping lgtvcommon.com, already processed.\n",
      "Skipping google.com.mx, already processed.\n",
      "Skipping intentiq.com, already processed.\n",
      "Skipping ameblo.jp, already processed.\n",
      "Skipping allegro.pl, already processed.\n",
      "Skipping rspamd.com, already processed.\n",
      "Skipping bytetcdn.com, already processed.\n",
      "Skipping bankofamerica.com, already processed.\n",
      "Skipping dreamhost.com, already processed.\n",
      "Skipping worldbank.org, already processed.\n",
      "Skipping ad.gt, already processed.\n",
      "Skipping ndtv.com, already processed.\n",
      "Skipping whitehouse.gov, already processed.\n",
      "Skipping academia.edu, already processed.\n",
      "Skipping supercell.com, already processed.\n",
      "Skipping flashtalking.com, already processed.\n",
      "Skipping withgoogle.com, already processed.\n",
      "Skipping google.com.tr, already processed.\n",
      "Skipping aniview.com, already processed.\n",
      "Skipping pornhub.com, already processed.\n",
      "Skipping me.com, already processed.\n",
      "Skipping mozilla.net, already processed.\n",
      "Skipping upravel.com, already processed.\n",
      "Skipping squarespacedns.com, already processed.\n",
      "Skipping arcgis.com, already processed.\n",
      "Skipping unpkg.com, already processed.\n",
      "Skipping va.gov, already processed.\n",
      "Skipping primevideo.com, already processed.\n",
      "Skipping amazon.it, already processed.\n",
      "Skipping alidns.com, already processed.\n",
      "Skipping seznam.cz, already processed.\n",
      "Skipping adjust.com, already processed.\n",
      "Skipping nest.com, already processed.\n",
      "Skipping kahoot.it, already processed.\n",
      "Skipping firebaseio.com, already processed.\n",
      "Skipping awswaf.com, already processed.\n",
      "Skipping sonobi.com, already processed.\n",
      "Skipping xerox.com, already processed.\n",
      "Skipping service-now.com, already processed.\n",
      "Skipping abovedomains.com, already processed.\n",
      "Skipping disneyplus.com, already processed.\n",
      "Skipping hindustantimes.com, already processed.\n",
      "Skipping apigee.net, already processed.\n",
      "Skipping spamhaus.org, already processed.\n",
      "Skipping genius.com, already processed.\n",
      "Skipping daum.net, already processed.\n",
      "Skipping firefox.com, already processed.\n",
      "Skipping state.gov, already processed.\n",
      "Skipping mirtesen.ru, already processed.\n",
      "Skipping welt.de, already processed.\n",
      "Skipping wp.pl, already processed.\n",
      "Skipping deloitte.com, already processed.\n",
      "Skipping chaturbate.com, already processed.\n",
      "Skipping biblegateway.com, already processed.\n",
      "Skipping statcounter.com, already processed.\n",
      "Skipping chartbeat.net, already processed.\n",
      "Skipping typeform.com, already processed.\n",
      "Skipping btloader.com, already processed.\n",
      "Skipping otto.de, already processed.\n",
      "Skipping mckinsey.com, already processed.\n",
      "Skipping atlassian.net, already processed.\n",
      "Skipping lg.com, already processed.\n",
      "Skipping yimg.com, already processed.\n",
      "Skipping ecdns.net, already processed.\n",
      "Skipping dnsv1.com, already processed.\n",
      "Skipping smartthings.com, already processed.\n",
      "Skipping markmonitor.com, already processed.\n",
      "Skipping msecnd.net, already processed.\n",
      "Skipping vivo.com.cn, already processed.\n",
      "Skipping tabtab-staging.com, already processed.\n",
      "Skipping tokopedia.com, already processed.\n",
      "Skipping arxiv.org, already processed.\n",
      "Skipping segment.io, already processed.\n",
      "Skipping discogs.com, already processed.\n",
      "Skipping nhk.or.jp, already processed.\n",
      "Skipping ui-dns.com, already processed.\n",
      "Skipping economist.com, already processed.\n",
      "Skipping apple.news, already processed.\n",
      "Skipping 2gis.com, already processed.\n",
      "Skipping realtor.com, already processed.\n",
      "Skipping docker.io, already processed.\n",
      "Skipping lowes.com, already processed.\n",
      "Skipping linode.com, already processed.\n",
      "Skipping attn.tv, already processed.\n",
      "Skipping amazon.com.br, already processed.\n",
      "Skipping kohls.com, already processed.\n",
      "Skipping churnzero.net, already processed.\n",
      "Skipping mdpi.com, already processed.\n",
      "Skipping ohthree.com, already processed.\n",
      "Skipping nintendo.com, already processed.\n",
      "Skipping tinkoff.ru, already processed.\n",
      "Skipping repubblica.it, already processed.\n",
      "Skipping mob.com, already processed.\n",
      "Skipping hm.com, already processed.\n",
      "Skipping adobedc.net, already processed.\n",
      "Skipping columbia.edu, already processed.\n",
      "Skipping exelator.com, already processed.\n",
      "Skipping spotifycdn.com, already processed.\n",
      "Skipping adgrx.com, already processed.\n",
      "Skipping postrelease.com, already processed.\n",
      "Skipping samsungcloudsolution.net, already processed.\n",
      "Skipping adroll.com, already processed.\n",
      "Attempt 1 to fetch Pixel ID from usnews.com\n",
      "Error fetching Pixel ID from usnews.com: Message: timeout: Timed out receiving message from renderer: -0.003\n",
      "  (Session info: chrome-headless-shell=122.0.6261.111)\n",
      "Stacktrace:\n",
      "#0 0x5e8b348c8f33 <unknown>\n",
      "#1 0x5e8b345c0ce6 <unknown>\n",
      "#2 0x5e8b345a8071 <unknown>\n",
      "#3 0x5e8b345a7db3 <unknown>\n",
      "#4 0x5e8b345a6814 <unknown>\n",
      "#5 0x5e8b345a6f1f <unknown>\n",
      "#6 0x5e8b345b7185 <unknown>\n",
      "#7 0x5e8b345cc8ac <unknown>\n",
      "#8 0x5e8b345d1e8b <unknown>\n",
      "#9 0x5e8b345a75ae <unknown>\n",
      "#10 0x5e8b345cc624 <unknown>\n",
      "#11 0x5e8b3464c762 <unknown>\n",
      "#12 0x5e8b3462dc53 <unknown>\n",
      "#13 0x5e8b345fedb3 <unknown>\n",
      "#14 0x5e8b345ff77e <unknown>\n",
      "#15 0x5e8b3488e86b <unknown>\n",
      "#16 0x5e8b34892885 <unknown>\n",
      "#17 0x5e8b3487c181 <unknown>\n",
      "#18 0x5e8b34893412 <unknown>\n",
      "#19 0x5e8b3486025f <unknown>\n",
      "#20 0x5e8b348b7528 <unknown>\n",
      "#21 0x5e8b348b7723 <unknown>\n",
      "#22 0x5e8b348c80e4 <unknown>\n",
      "#23 0x718d2d294ac3 <unknown>\n",
      "\n",
      "Retrying in 5 seconds...\n",
      "Attempt 2 to fetch Pixel ID from usnews.com\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getPixelID(website, driver, max_retries=5, delay=5):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempt {attempt + 1} to fetch Pixel ID from {website}\")\n",
    "\n",
    "            time.sleep(4.5)\n",
    "            if not website.startswith(('http://', 'https://')): #Adding the protocol since the tranco list does not contain the schema in the urls\n",
    "                try:\n",
    "                    driver.get('https://' + website)\n",
    "                except:\n",
    "                    driver.get('http://' + website)\n",
    "                \n",
    "            else:\n",
    "                driver.get(website)\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            scripts = soup.find_all('script')\n",
    "\n",
    "            pattern = re.compile(r'connect\\.facebook\\.net/signals/config/(\\d+)')\n",
    "            \n",
    "            for script in scripts:\n",
    "                if script.has_attr('src'):\n",
    "                    src = script['src']\n",
    "                    if \"connect.facebook.net/signals/config\" in src:\n",
    "                        match = pattern.search(src)\n",
    "                        if match:\n",
    "                            print(f\"Pixel ID found: {match.group(1)}\")\n",
    "                            return match.group(1)\n",
    "            \n",
    "            print(f\"No Pixel ID found on {website}\")\n",
    "            return None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching Pixel ID from {website}: {e}\")\n",
    "            print(f\"Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "    print(f\"Failed to fetch Pixel ID from {website} after {max_retries} attempts.\")\n",
    "    return None\n",
    "\n",
    "def get_wayback_snapshot(website, date, max_retries=5):\n",
    "    url = f\"http://archive.org/wayback/available?url={website}&timestamp={date}\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempt {attempt + 1}: Getting snapshot for {date}\")\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if 'archived_snapshots' in data and data['archived_snapshots']:\n",
    "                return data['archived_snapshots']['closest']['url']\n",
    "            return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}. Retrying in 3 seconds...\")\n",
    "            time.sleep(5)\n",
    "    print(f\"Failed to get snapshot for {date} after {max_retries} attempts.\")\n",
    "    return None\n",
    "\n",
    "def check_past_versions(website, driver):\n",
    "    current_date = datetime.now()\n",
    "    for i in range(1,2): #set to 60 later for going back every month for 5 years\n",
    "        past_date = (current_date - timedelta(days=i*600)).strftime('%Y%m%d') #set days i*30 for 1 month\n",
    "        snapshot_url = get_wayback_snapshot(website, past_date)\n",
    "        if snapshot_url:\n",
    "            print(f\"Searching snapshot: {snapshot_url}\")\n",
    "            pixelID = getPixelID(snapshot_url, driver)\n",
    "            if pixelID:\n",
    "                print(f\"Found pixel ID: {pixelID} at the snapsot: {past_date} \")\n",
    "                return pixelID, past_date\n",
    "    return None, None\n",
    "\n",
    "def load_progress(filename):\n",
    "    if os.path.exists(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"Website Name\", \"Pixel ID\", \"Fetched Date\"])\n",
    "\n",
    "def save_progress(df, filename):\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "def populateDataframe(urls, progress_file):\n",
    "    # Load previous progress if any\n",
    "    progress_df = load_progress(progress_file)\n",
    "    completed_urls = progress_df['Website Name'].tolist()\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    total_urls = len(urls)\n",
    "    \n",
    "    for idx, website in enumerate(urls):\n",
    "        if website in completed_urls:\n",
    "            print(f\"Skipping {website}, already processed.\")\n",
    "            continue\n",
    "        \n",
    "        # Process the URL\n",
    "        pixelID = getPixelID(website, driver)\n",
    "        print(\"Pixel ID fetched directly: \",pixelID)\n",
    "        fetch_date = datetime.now().strftime('%Y%m%d')  # Use current date if found in current version\n",
    "\n",
    "        if not pixelID:  # If no pixel ID found, check Wayback Machine\n",
    "            pixelID, past_date = check_past_versions(website, driver)\n",
    "            fetch_date = past_date if past_date else fetch_date  # Use past date if found in Wayback Machine\n",
    "        \n",
    "        # Append the result to the DataFrame\n",
    "        new_record = {\"Website Name\": website, \"Pixel ID\": pixelID, \"Fetched Date\": fetch_date}\n",
    "        progress_df = pd.concat([progress_df, pd.DataFrame([new_record])], ignore_index=True)\n",
    "\n",
    "        # Save progress after each URL is processed\n",
    "        save_progress(progress_df, progress_file)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Processed {idx + 1}/{total_urls}: {website} (Pixel ID: {pixelID})\")\n",
    "\n",
    "    driver.quit()\n",
    "    return progress_df\n",
    "\n",
    "\n",
    "progress_file = 'scraping_progress.csv'\n",
    "urls = pd.read_csv('tranco_top_10k.csv')['website'].to_list()\n",
    "\n",
    "df = populateDataframe(urls, progress_file)\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
